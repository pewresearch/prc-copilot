### 11. Demo Overview

The WordPress Feature API Agent Demo (`demo/wp-feature-api-agent/`) is a functional example plugin showcasing how the WordPress Feature API can allow AI agents to interact with WordPress. It demonstrates an architecture where a client-side agent orchestrator communicates with a backend PHP proxy, which in turn interacts with ChatGPT. The key concept illustrated is how WordPress Features (both server-side and client-side) can be exposed as "tools" for the LLM to use, enabling conversational control over WordPress functionality.

## Key Concepts Illustrated

The demo illustrates several core concepts of the WordPress Feature API:

1. **Feature Registration** - Examples of registering both resource and tool features
2. **Server-Client Communication** - Demonstrating how server and client can exchange capabilities
3. **Feature Discovery** - How features can be discovered and executed programmatically
4. **Schema Definition** - Using JSON Schema to define inputs and outputs
5. **Permission Control** - Implementing permission callbacks for features
6. **Eligibility Checks** - Using conditional checks to determine if a feature should be available
7. **Conversational Interface** - A practical implementation showing how AI agents can interact with features

## Technical Implementation

### Architecture

The demo follows a clean architecture pattern divided into several key components:

1. **Core Plugin** (`wp-feature-api-agent.php`): Initializes the demo, loads dependencies, and enqueues assets.
2. **Backend Proxy** (`includes/class-wp-ai-api-proxy.php`): Handles REST API requests from the client, communicates with the configured LLM API, and injects discovered tools.
3. **Configuration** (`includes/class-wp-ai-api-options.php`): Manages settings for API keys.
4. **Feature Registration** (`includes/class-wp-feature-register.php`): Registers demo-specific server-side features (e.g., `demo/site-info`).
5. **Client-Side Agent Orchestrator** (`src/agent/orchestrator.ts`): Manages the conversation loop, calls the backend proxy, processes LLM responses (including tool calls), and coordinates tool execution.
6. **Tool Executor** (`src/agent/tool-executor.ts`): Responsible for executing specific tools (features) when requested by the orchestrator.
7. **Tool Provider** (`src/agent/wp-feature-tool-provider.ts`): Discovers available WordPress features (server and client-side) and makes them available to the `ToolExecutor`.
8. **React UI** (`src/index.tsx`, `src/components/`, `src/context/`): Provides the conversational interface (chat window) in the WordPress admin, powered by React components and context for state management.

### Server-Side Features

The demo registers a simple server-side resource feature:

```php
// In includes/class-wp-feature-register.php
wp_register_feature(
    array(
        'id'          => 'demo/site-info',
        'name'        => __( 'Site Information', 'wp-feature-api-agent' ),
        'description' => __( 'Get basic information about the WordPress site. This includes the name, description, URL, version, language, timezone, date format, time format, active plugins, and active theme.', 'wp-feature-api-agent' ),
        'type'        => WP_Feature::TYPE_RESOURCE,
        'categories'  => array( 'demo', 'site', 'information' ),
        'callback'    => array( $this, 'site_info_callback' ),
    )
);
```

While this demo only includes one specific example, the `WpFeatureToolProvider` will automatically discover *any* feature registered via `wp_register_feature` or the client-side feature registration mechanisms, making them available as tools to the agent.

### Client-Side Implementation

The client-side is built with React and TypeScript:

- **UI Components:** `ChatApp.tsx` provides the main chat window structure, `ChatMessage.tsx` renders individual messages.
- **State Management:** `ConversationProvider.tsx` uses React Context to manage the message history, loading state, and provides the `sendMessage` function. It also initializes the agent orchestrator and tool executor.
- **Agent Logic:**
  - `orchestrator.ts`: Contains the core `processQuery` async generator function that handles the conversation loop, API calls, and tool call processing.
  - `tool-executor.ts`: Defines the `ToolExecutor` class responsible for calling the appropriate tool provider.
  - `wp-feature-tool-provider.ts`: Implements the logic to find and execute WordPress features based on their ID, interacting with the core Feature API (likely via `@wordpress/client` utilities or direct REST calls).

### Chat Interface

The demo includes a conversational interface implemented as a React application embedded in the WordPress admin area. It:

1. Allows users to send natural language messages
2. Routes messages to a simple agent implementation
3. Maps user intent to available features
4. Executes features and returns results
5. Handles client-side feature execution via tool calls
6. Maintains conversation context

This interface demonstrates how AI agents can leverage WordPress features discovered through the API to fulfill user requests.

## Key Ideas and Patterns

### LLM Tool Use via Feature API

The core idea is using the Feature API as a bridge to allow LLMs to interact with WordPress functionality in a structured way. Features become tools the LLM can request, enabling complex actions based on natural language.

### Agent Orchestration

The demo implements a client-side orchestration pattern. The orchestrator manages the flow between the user interface, the backend LLM proxy, and the tool execution system. This keeps the client responsive and allows for complex multi-step interactions involving tool calls.

### Backend Proxy Pattern

Using a PHP backend proxy (`WP_AI_API_Proxy`) provides several benefits:

- **Security:** API keys for the external LLM service are kept on the server, not exposed to the browser.
- **Control:** The proxy can enforce rules, inject context (like available tools), and manage API interactions.
- **Abstraction:** The client-side code interacts with a consistent WordPress REST API endpoint, regardless of the specific LLM service used on the backend.

## Installation and Usage

1. Ensure the main WordPress Feature API plugin is installed and activated.
2. **Configure AI Service:** Navigate to the settings page added by the demo (under "Settings" > "Feature API Demo") and enter your API key for OpenAI.
3. Try natural language requests like:
    - "Tell me about this site." (Uses the `demo/site-info` feature)
    - "What WordPress version is this?"
    - "Create a post based on my site info."
